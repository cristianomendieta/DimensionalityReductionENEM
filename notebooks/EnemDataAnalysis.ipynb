{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install -U scikit-learn==1.3.2\n",
        "# !pip install umap-learn\n",
        "# !pip install pacmap\n",
        "# !pip install matplotlib\n",
        "# !pip install seaborn\n",
        "\n",
        "# !pip list | grep pacmap\n",
        "# !pip list | grep pandas\n",
        "# !pip list | grep umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPak-SWOvyFp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKyK6yadwQDI",
        "outputId": "68016a55-07ec-40c4-8e9d-5c60a95a7199"
      },
      "outputs": [],
      "source": [
        "# run on colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWyJI7wJwUZe"
      },
      "outputs": [],
      "source": [
        "base_path = '/home/cristiano/ufpr/tcc/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7n_wbksw3xj"
      },
      "outputs": [],
      "source": [
        "df_microdados = pd.read_csv(f'{base_path}/MICRODADOS_ENEM_2022.csv', sep=';', encoding='ISO-8859-1')\n",
        "# df_itens_prova = pd.read_csv(f'{base_path}/ITENS_PROVA_2022.csv', sep=';', encoding='ISO-8859-1')\n",
        "# df_quest_hab = pd.read_csv(f'{base_path}/QUEST_HAB_ESTUDO.csv', sep=';', encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNB3eujqv99n"
      },
      "outputs": [],
      "source": [
        "# df_microdados = df_microdados_original.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctmK2lBeAqB-",
        "outputId": "e61be282-93d3-40ea-9368-9247af75041b"
      },
      "outputs": [],
      "source": [
        "df_microdados.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DujqgTq2Bmqt",
        "outputId": "c0177403-d66e-4d23-a0f1-ec7cd77d2429"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# cntagem de valores nulos por coluna\n",
        "valores_nulos_por_coluna = df_microdados.isnull().sum()\n",
        "\n",
        "# Filtrar apenas as colunas com valores nulos\n",
        "colunas_com_valores_nulos = valores_nulos_por_coluna[valores_nulos_por_coluna > 0]\n",
        "\n",
        "# Exibindo os resultados\n",
        "print(colunas_com_valores_nulos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "43uKW-fZxe6S",
        "outputId": "165f798d-09b4-4f78-c69f-27ced5c8fb57"
      },
      "outputs": [],
      "source": [
        "df_microdados.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbyukLMOyt9b"
      },
      "outputs": [],
      "source": [
        "# print(f'dimensão microdados: {df_microdados.shape}\\ndimensão itens prova{df_itens_prova.shape}\\ndimensão quest hab {df_quest_hab.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0oJuJbRztTK",
        "outputId": "d52f8e9a-2c64-4de8-81a7-e1e186664301"
      },
      "outputs": [],
      "source": [
        "df_microdados.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqutIdRijglM"
      },
      "source": [
        "Colunas\n",
        "- NU_INSCRICAO: id\n",
        "- NU_ANO -> remover\n",
        "- TP_FAIXA_ETARIA: faixa etária(1 a 20)\n",
        "- TP_SEXO -> M OU F\n",
        "- TP_ESTADO_CIVIL: 0 A 4\n",
        "- TP_COR_RACA: 0 A 6\n",
        "- TP_NACIONALIDADE: 0 A 4\n",
        "- TP_ST_CONCLUSAO: status conclusão ensino medio(1 a 4)\n",
        "- TP_ANO_CONCLUIU: 0 A 16\n",
        "- TP_ESCOLA: 1 a 3(possível target)\n",
        "- TP_ENSINO: 1 OU 2\n",
        "- IN_TREINEIRO: 1 OU 0\n",
        "- CO_MUNICIPIO_ESC: codigo municipio escola\n",
        "- NO_MUNICIPIO_ESC: Nome\n",
        "- CO_UF_ESC: codigo da unidade da federação da escola\n",
        "- SG_UF_ESC: sigla uf da escola\n",
        "- TP_DEPENDENCIA_ADM_ESCOLA: 1 a 4\n",
        "- TP_LOCALIZACAO_ESC: 1 ou 2(urbana ou rural)\n",
        "- TP_SIT_FUNC_ESC: situacao de funcionamento(1 a 4)\n",
        "- CO_MUNICIPIO_PROVA: código da cidade onde a prova foi aplicada\n",
        "- NO_MUNICIPIO_PROVA: nome\n",
        "- CO_UF_PROVA: codigo uf\n",
        "- SG_UF_PROVA: sigla da uf\n",
        "- TP_PRESENCA_CN\n",
        "- TP_PRESENCA_CH\n",
        "- TP_PRESENCA_LC\n",
        "- TP_PRESENCA_MT: 0 A 2\n",
        "- CO_PROVA_CN\n",
        "- CO_PROVA_CH\n",
        "- CO_PROVA_LC\n",
        "- CO_PROVA_MT: código das provas(já é numérico)\n",
        "- NU_NOTA_CN\n",
        "- NU_NOTA_CH\n",
        "- NU_NOTA_LC\n",
        "- NU_NOTA_MT: notas(númerica)  \n",
        "- TX_RESPOSTAS_CN\n",
        "- TX_RESPOSTAS_CH\n",
        "- TX_RESPOSTAS_LC\n",
        "- TX_RESPOSTAS_MT: vetores com as respostas(não usar)\n",
        "\n",
        "- TP_LINGUA: ingles ou espanhol(0 ou 1)\n",
        "\n",
        "- TX_GABARITO_CN\n",
        "- TX_GABARITO_CH\n",
        "- TX_GABARITO_LC\n",
        "- TX_GABARITO_MT: vetores com o gabarito(não usar)\n",
        "\n",
        "- TP_STATUS_REDACAO: status redação(1 a 9)\n",
        "\n",
        "- NU_NOTA_COMP1\n",
        "- NU_NOTA_COMP2\n",
        "- NU_NOTA_COMP3\n",
        "- NU_NOTA_COMP4\n",
        "- NU_NOTA_COMP5: notas de competências da redação\n",
        "\n",
        "- NU_NOTA_REDACAO: nota redaçao\n",
        "\n",
        "- questões socieconômicas: alternativas alfanuméricas\n",
        "##### target inicial -> Q006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C8Yd7of5KZb",
        "outputId": "cc51999c-eea8-4206-c126-e2222f5c1136"
      },
      "outputs": [],
      "source": [
        "df_microdados.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tqCDGJ7l5YBj"
      },
      "outputs": [],
      "source": [
        "descartar = [\n",
        "    'NU_INSCRICAO', \n",
        "    'NU_ANO', \n",
        "    'TX_RESPOSTAS_CN', \n",
        "    'TX_RESPOSTAS_CH', \n",
        "    'TX_RESPOSTAS_LC',\n",
        "    'TX_RESPOSTAS_MT',\n",
        "    'TX_GABARITO_CN', \n",
        "    'TX_GABARITO_CH',\n",
        "    'TX_GABARITO_LC', \n",
        "    'TX_GABARITO_MT', \n",
        "    'TP_ENSINO',              \n",
        "    'CO_MUNICIPIO_ESC',       \n",
        "    'NO_MUNICIPIO_ESC',       \n",
        "    'CO_UF_ESC',              \n",
        "    'SG_UF_ESC',              \n",
        "    'TP_DEPENDENCIA_ADM_ESC', \n",
        "    'TP_LOCALIZACAO_ESC',     \n",
        "    'TP_SIT_FUNC_ESC',        \n",
        "    'CO_PROVA_CN',            \n",
        "    'CO_PROVA_CH',            \n",
        "    'CO_PROVA_LC',            \n",
        "    'CO_PROVA_MT'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(descartar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "zerar_colunas = [\"NU_NOTA_CN\", \"NU_NOTA_CH\", \"NU_NOTA_LC\", \"NU_NOTA_MT\", \"NU_NOTA_REDACAO\", \"NU_NOTA_COMP1\", \"NU_NOTA_COMP2\", \"NU_NOTA_COMP3\", \"NU_NOTA_COMP4\", \"NU_NOTA_COMP5\", \"TP_STATUS_REDACAO\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_microdados = df_microdados.drop(columns=descartar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_microdados[zerar_colunas] = df_microdados[zerar_colunas].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_exlui = df_microdados.dropna()\n",
        "# df_microdados.shape[0] == df_exlui.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpLoH0dSDoJJ",
        "outputId": "4061c567-528d-4b08-d512-20b0264857c4"
      },
      "outputs": [],
      "source": [
        "# proporção de dados que contém algum dado nulo (ANTIGO)\n",
        "# 681900 / 3476105"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdOo7T5RuAZR",
        "outputId": "2c7469f8-a687-4690-cfff-d97d7c4a9853"
      },
      "outputs": [],
      "source": [
        "df_microdados.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_microdados.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PN-6oanu413"
      },
      "outputs": [],
      "source": [
        "df_microdados.rename(columns={'Q006': 'faixa_renda_familiar'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_microdados.to_parquet('./data/data_prepared_enem_2022.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### UTILZAR DADOS JÁ PREPARADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_microdados = pd.read_parquet('./data/data_prepared_enem_2022.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_microdados['TP_ESCOLA'].value_counts()\n",
        "\n",
        "### muitos dados não informados -> não considerar esses registros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wfijRXxuQHb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_microdados.drop('faixa_renda_familiar', axis=1)\n",
        "y = df_microdados['faixa_renda_familiar']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3GuvnNmviRc"
      },
      "outputs": [],
      "source": [
        "# X.columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet('/home/cristiano/ufpr/tcc/train_data/binaria/X_train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1054048, 53)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rp-nEoYjrgIG"
      },
      "outputs": [],
      "source": [
        "del df_microdados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeVPK4V3yJfp"
      },
      "outputs": [],
      "source": [
        "numeric_cols = [\n",
        "    \"TP_FAIXA_ETARIA\",\n",
        "    \"TP_ESTADO_CIVIL\",\n",
        "    \"TP_COR_RACA\",\n",
        "    \"TP_NACIONALIDADE\",\n",
        "    \"TP_ST_CONCLUSAO\",\n",
        "    \"TP_ANO_CONCLUIU\",\n",
        "    \"TP_ESCOLA\",\n",
        "    \"IN_TREINEIRO\",\n",
        "    \"CO_MUNICIPIO_PROVA\",\n",
        "    \"CO_UF_PROVA\",\n",
        "    \"TP_PRESENCA_CN\",\n",
        "    \"TP_PRESENCA_CH\",\n",
        "    \"TP_PRESENCA_LC\",\n",
        "    \"TP_PRESENCA_MT\",\n",
        "    \"NU_NOTA_CN\",\n",
        "    \"NU_NOTA_CH\",\n",
        "    \"NU_NOTA_LC\",\n",
        "    \"NU_NOTA_MT\",\n",
        "    \"TP_LINGUA\",\n",
        "    \"NU_NOTA_REDACAO\",\n",
        "    'NU_NOTA_COMP1',\n",
        "    'NU_NOTA_COMP2',\n",
        "    'NU_NOTA_COMP3',\n",
        "    'NU_NOTA_COMP4',\n",
        "    'NU_NOTA_COMP5',\n",
        "    \"Q005\"\n",
        "]\n",
        "\n",
        "categorical_cols = [\n",
        "    \"TP_SEXO\",\n",
        "    \"Q001\",\n",
        "    \"Q002\",\n",
        "    \"Q003\",\n",
        "    \"Q004\",\n",
        "    \"Q007\",\n",
        "    \"Q008\",\n",
        "    \"Q009\",\n",
        "    \"Q010\",\n",
        "    \"Q011\",\n",
        "    \"Q012\",\n",
        "    \"Q013\",\n",
        "    \"Q014\",\n",
        "    \"Q015\",\n",
        "    \"Q016\",\n",
        "    \"Q017\",\n",
        "    \"Q018\",\n",
        "    \"Q019\",\n",
        "    \"Q020\",\n",
        "    \"Q021\",\n",
        "    \"Q022\",\n",
        "    \"Q023\",\n",
        "    \"Q024\",\n",
        "    \"Q025\",\n",
        "    \"NO_MUNICIPIO_PROVA\",\n",
        "    \"TP_STATUS_REDACAO\",\n",
        "    \"SG_UF_PROVA\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(numeric_cols + categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set(list(X.columns)) - set(numeric_cols + categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkFwmafTweu1"
      },
      "outputs": [],
      "source": [
        "# all_columns = X.columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbbkZcWWyvAG",
        "outputId": "d342594a-bfdb-4959-874b-cbfb7a6b88d7"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX27sx0t1jcf",
        "outputId": "0cb2a8a2-c103-4eb0-a86b-53650f5b3480"
      },
      "outputs": [],
      "source": [
        "y.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvIm9zLTz25O",
        "outputId": "add8d5a2-f2a6-49ec-ee13-cf4155f3d6c4"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWa-eug73I11"
      },
      "source": [
        "### Pré-processamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt4cNLiR23i_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = pd.DataFrame(y_train)\n",
        "y_train.to_parquet('/home/cristiano/ufpr/tcc/classificacao_multiclasse/y_train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test = pd.DataFrame(y_test)\n",
        "y_test.to_parquet('/home/cristiano/ufpr/tcc/classificacao_multiclasse/y_test.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train.to_parquet('./use_data/X_train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXVymDwMbZAX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA, TruncatedSVD, FastICA, KernelPCA\n",
        "from sklearn.manifold import TSNE\n",
        "from umap import UMAP\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pacmap\n",
        "\n",
        "\n",
        "def generate_pipeline(method, n_components=None):\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('scaler', MinMaxScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('encoder', OrdinalEncoder())\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols),\n",
        "        ])\n",
        "\n",
        "    if method == 'nan':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor)\n",
        "        ])\n",
        "\n",
        "    elif method == 'pca':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('reduction_method', PCA(n_components=n_components))\n",
        "        ])\n",
        "\n",
        "    elif method == 'svd':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('reduction_method', TruncatedSVD(n_components=n_components))\n",
        "        ])\n",
        "\n",
        "    elif method == 'ica':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('reduction_method', FastICA(n_components=n_components))\n",
        "        ])\n",
        "\n",
        "    ### não será utilizado pois não é eficiente para um conjunto de dados com muitas linhas como é o nosso caso, no algoritmo do kpca a dimensionalidade é aumentada\n",
        "    ### e nesse caso como temos mais de 3 milhões de linhas, o algoritmo não é eficiente\n",
        "    \n",
        "    elif method == 'kernel_pca':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('reduction_method', KernelPCA(n_components=n_components, kernel='rbf', gamma=10, alpha=0.1))\n",
        "        ])\n",
        "\n",
        "    elif method == 'tsne':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('pre_tsne', PCA(n_components=5)),\n",
        "            ('reduction_method', TSNE(n_components=n_components, random_state=42))\n",
        "        ])\n",
        "\n",
        "    elif method == 'umap':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('reduction_method', UMAP(n_components=n_components, random_state=42))\n",
        "        ])\n",
        "        \n",
        "    elif method == 'pacmap':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('reduction_method', pacmap.PaCMAP(n_components=n_components, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=42))\n",
        "        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhINsER-3Ux_"
      },
      "source": [
        "#### Resultados Redução de dimensionalidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQd-CK5v5Snq"
      },
      "outputs": [],
      "source": [
        "##### Não será mais utilizado, visto que faz sentido apenas para métodos como PCA e SVD\n",
        "\n",
        "import numpy as np\n",
        "def get_preserved_variance_ratio(X, X_transformed):\n",
        "    # Calcula a variância total dos dados originais\n",
        "    total_variance = np.var(X, axis=0).sum()\n",
        "\n",
        "    # Calcula a variância após a redução de dimensionalidade\n",
        "    reduced_variance = np.var(X_transformed, axis=0).sum()\n",
        "\n",
        "    # Calcula a proporção da variância preservada\n",
        "    preserved_variance_ratio = reduced_variance / total_variance\n",
        "\n",
        "    return preserved_variance_ratio\n",
        "\n",
        "### faz sentido aplicar para todos os métodos de redução de dimensionalidade?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "def get_preserved_proximity(X, X_transformed):\n",
        "    # Calcular as distâncias euclidianas nos espaços original e reduzido\n",
        "    dist_original = euclidean_distances(X)\n",
        "    dist_tsne = euclidean_distances(X_transformed)\n",
        "\n",
        "    # Calcular a preservação da estrutura de proximidade\n",
        "    preservation = np.abs(dist_original - dist_tsne).mean()\n",
        "\n",
        "    return preservation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuL950R4g0AN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "\n",
        "def get_linear_methods_results(list_methods, n_components_list, X_train):\n",
        "    results = []\n",
        "\n",
        "    for method in list_methods:\n",
        "        for n in n_components_list:\n",
        "            print(f\"Method: {method} - n_components: {n}\")\n",
        "            # dr is short for dimensionality reduction\n",
        "            pipeline_dr = generate_pipeline(method, n)\n",
        "            pipeline_without_dr = generate_pipeline('nan')\n",
        "\n",
        "            start_time = time.time()\n",
        "            \n",
        "            X_train_transformed_dr = pipeline_dr.fit_transform(X_train)\n",
        "\n",
        "            end_time = time.time()\n",
        "            execution_time = end_time - start_time\n",
        "\n",
        "            print(f\"Execution time: {execution_time} seconds\")\n",
        "\n",
        "            X_train_transformed = pipeline_without_dr.fit_transform(X_train)\n",
        "\n",
        "            X_restored = pipeline_dr.named_steps['reduction_method'].inverse_transform(X_train_transformed_dr)\n",
        "\n",
        "            reduction_method_mse = mean_squared_error(X_train_transformed, X_restored)\n",
        "\n",
        "            # save X_train_transformed_dr as parquet\n",
        "            X_train_transformed_dr_df = pd.DataFrame(X_train_transformed_dr)\n",
        "\n",
        "            results.append({\n",
        "                'Method': method,\n",
        "                'n_components': n,\n",
        "                'MSE': reduction_method_mse,\n",
        "                'time': execution_time\n",
        "            })\n",
        "\n",
        "            del pipeline_dr\n",
        "            del pipeline_without_dr\n",
        "            del X_train_transformed_dr\n",
        "            del X_train_transformed\n",
        "            del X_restored\n",
        "            gc.collect()\n",
        "\n",
        "    # Convertendo a lista de dicionários em um DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_non_linear_methods_results(list_methods, n_components_list, X_train):\n",
        "    results = []\n",
        "\n",
        "    for method in list_methods:\n",
        "        for n in n_components_list:\n",
        "            print(f\"Method: {method} - n_components: {n}\")\n",
        "            # dr is short for dimensionality reduction\n",
        "            pipeline_dr = generate_pipeline(method, n)\n",
        "            pipeline_without_dr = generate_pipeline('nan')\n",
        "\n",
        "            start_time = time.time()\n",
        "            \n",
        "            X_train_transformed_dr = pipeline_dr.fit_transform(X_train)\n",
        "\n",
        "            end_time = time.time()\n",
        "            execution_time = end_time - start_time\n",
        "\n",
        "            print(f\"Execution time: {execution_time} seconds\")\n",
        "\n",
        "            X_train_transformed = pipeline_without_dr.fit_transform(X_train)\n",
        "\n",
        "            # save X_train_transformed_dr as parquet\n",
        "            X_train_transformed_dr_df = pd.DataFrame(X_train_transformed_dr)\n",
        "            \n",
        "            preservation = get_preserved_proximity(X_train_transformed, X_train_transformed_dr)\n",
        "\n",
        "            results.append({\n",
        "                'Method': method,\n",
        "                'n_components': n,\n",
        "                'preserved_proximity': preservation,\n",
        "                'time': execution_time\n",
        "            })\n",
        "\n",
        "            del pipeline_dr\n",
        "            del pipeline_without_dr\n",
        "            del X_train_transformed_dr\n",
        "            del X_train_transformed\n",
        "\n",
        "            gc.collect()\n",
        "\n",
        "    # Convertendo a lista de dicionários em um DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUhARmrSeVOU"
      },
      "outputs": [],
      "source": [
        "list_linear_methods = [\"pca\", \"svd\", \"ica\"]\n",
        "n_components_list = [2, 3, 5, 10, 20, 30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet('/home/cristiano/ufpr/results/linear_metrics.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_linear_methods = get_linear_methods_results(list_linear_methods, n_components_list, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_linear_methods = [\"umap\"]\n",
        "n_components_list = [2]\n",
        "\n",
        "df_results_non_linear_methods_umap = get_dimension_reduction_results(non_linear_methods, n_components_list, X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tGKhswU7-Aq"
      },
      "source": [
        "### Análise de métricas redução de dimensionalidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5b-LahZutLC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_linear_results = pd.read_parquet('/home/cristiano/ufpr/results/linear_metrics.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_linear_results.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Análise Métodos lineares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "metodos = df_linear_results['Method'].unique()\n",
        "n_componentes = df_linear_results['n_components']\n",
        "variancia_preservada = df_linear_results['Preserved Variance Ratio']\n",
        "\n",
        "mse = df_linear_results['MSE']\n",
        "tempo_duracao = df_linear_results['time']\n",
        "\n",
        "# Plotando gráficos de linhas individuais para cada método e métrica\n",
        "for metodo in metodos:\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Gráfico de Linhas para MSE\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(n_componentes[df_linear_results['Method'] == metodo], \n",
        "             mse[df_linear_results['Method'] == metodo], \n",
        "             marker='o')\n",
        "    plt.title(f'MSE - {metodo}')\n",
        "    plt.xlabel('Número de Componentes')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Gráfico de Linhas para Tempo de Duração\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(n_componentes[df_linear_results['Method'] == metodo], \n",
        "             tempo_duracao[df_linear_results['Method'] == metodo], \n",
        "             marker='o')\n",
        "    plt.title(f'Tempo de Duração - {metodo}')\n",
        "    plt.xlabel('Número de Componentes')\n",
        "    plt.ylabel('Tempo de Duração (segundos)')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plotando gráficos comparativos para cada métrica\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Gráfico de Linhas para MSE\n",
        "plt.subplot(1, 3, 2)\n",
        "for metodo in metodos:\n",
        "    plt.plot(n_componentes[df_linear_results['Method'] == metodo], \n",
        "             mse[df_linear_results['Method'] == metodo], \n",
        "             marker='o', label=metodo)\n",
        "plt.title('MSE por Método de Redução de Dimensionalidade')\n",
        "plt.xlabel('Número de Componentes')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Gráfico de Linhas para Tempo de Duração\n",
        "plt.subplot(1, 3, 3)\n",
        "for metodo in metodos:\n",
        "    plt.plot(n_componentes[df_linear_results['Method'] == metodo], \n",
        "             tempo_duracao[df_linear_results['Method'] == metodo], \n",
        "             marker='o', label=metodo)\n",
        "plt.title('Tempo de Duração por Método de Redução de Dimensionalidade')\n",
        "plt.xlabel('Número de Componentes')\n",
        "plt.ylabel('Tempo de Duração (segundos)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualização dos Dados após redução de dimensionalidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_transformer = Pipeline(steps=[\n",
        "        ('encoder', OrdinalEncoder())\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_transformed = categorical_transformer.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_dimensionality_reduction(x, method_name):\n",
        "\n",
        "    \n",
        "    plt.hexbin(x[0], x[1], gridsize=30, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.title(f'Hexbin Scatter Plot - {method_name}')\n",
        "    plt.xlabel('Componente 1')\n",
        "    plt.ylabel('Componente 2')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"/home/cristiano/ufpr/results/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_pca = pd.read_parquet(f'{path}/X_train_transformed_dr_pca_2.parquet')\n",
        "data_svd = pd.read_parquet(f'{path}/X_train_transformed_dr_svd_2.parquet')\n",
        "data_ica = pd.read_parquet(f'{path}/X_train_transformed_dr_ica_2.parquet')\n",
        "\n",
        "data_tsne = pd.read_parquet(f'{path}/X_train_transformed_dr_tsne_2.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_pca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "data_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_dimensionality_reduction(data_pca, 'PCA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_dimensionality_reduction(data_svd, 'SVD')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_dimensionality_reduction(data_ica, 'ICA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_dimensionality_reduction(data_tsne, 'TSNE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classificação Multiclasse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Train Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_enem = pd.read_parquet(\"/home/cristiano/ufpr/tcc/data/data_prepared_enem_2022.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data_enem.drop('faixa_renda_familiar', axis=1)\n",
        "y = data_enem['faixa_renda_familiar']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.to_parquet('/home/cristiano/ufpr/tcc/train_data/multiclasse/X_train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = [\n",
        "    \"TP_FAIXA_ETARIA\",\n",
        "    \"TP_ESTADO_CIVIL\",\n",
        "    \"TP_COR_RACA\",\n",
        "    \"TP_NACIONALIDADE\",\n",
        "    \"TP_ST_CONCLUSAO\",\n",
        "    \"TP_ANO_CONCLUIU\",\n",
        "    \"TP_ESCOLA\",\n",
        "    \"IN_TREINEIRO\",\n",
        "    \"CO_MUNICIPIO_PROVA\",\n",
        "    \"CO_UF_PROVA\",\n",
        "    \"TP_PRESENCA_CN\",\n",
        "    \"TP_PRESENCA_CH\",\n",
        "    \"TP_PRESENCA_LC\",\n",
        "    \"TP_PRESENCA_MT\",\n",
        "    \"NU_NOTA_CN\",\n",
        "    \"NU_NOTA_CH\",\n",
        "    \"NU_NOTA_LC\",\n",
        "    \"NU_NOTA_MT\",\n",
        "    \"TP_LINGUA\",\n",
        "    \"NU_NOTA_REDACAO\",\n",
        "    'NU_NOTA_COMP1',\n",
        "    'NU_NOTA_COMP2',\n",
        "    'NU_NOTA_COMP3',\n",
        "    'NU_NOTA_COMP4',\n",
        "    'NU_NOTA_COMP5',\n",
        "    \"Q005\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Suponha que você tenha seus datasets X_train e y_train\n",
        "\n",
        "# Lista de colunas categóricas\n",
        "categorical_cols = [\n",
        "    \"TP_SEXO\",\n",
        "    \"Q001\",\n",
        "    \"Q002\",\n",
        "    \"Q003\",\n",
        "    \"Q004\",\n",
        "    \"Q007\",\n",
        "    \"Q008\",\n",
        "    \"Q009\",\n",
        "    \"Q010\",\n",
        "    \"Q011\",\n",
        "    \"Q012\",\n",
        "    \"Q013\",\n",
        "    \"Q014\",\n",
        "    \"Q015\",\n",
        "    \"Q016\",\n",
        "    \"Q017\",\n",
        "    \"Q018\",\n",
        "    \"Q019\",\n",
        "    \"Q020\",\n",
        "    \"Q021\",\n",
        "    \"Q022\",\n",
        "    \"Q023\",\n",
        "    \"Q024\",\n",
        "    \"Q025\",\n",
        "    \"NO_MUNICIPIO_PROVA\",\n",
        "    \"TP_STATUS_REDACAO\",\n",
        "    \"SG_UF_PROVA\"\n",
        "]\n",
        "\n",
        "# Pipeline para aplicar codificadores\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('ordinal_encoder', OrdinalEncoder(), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Crie o pipeline\n",
        "train_pipeline = Pipeline(steps=[    \n",
        "    ('preprocessor', preprocessor)\n",
        "])\n",
        "\n",
        "# Ajuste o pipeline ao conjunto de dados de treinamento\n",
        "X_train_encoded = train_pipeline.fit_transform(X_train)\n",
        "\n",
        "# Use LabelEncoder para codificar o alvo\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_transformed = train_pipeline.transform(X_test)\n",
        "y_test_transformed = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(silent=False, \n",
        "                      scale_pos_weight=1,\n",
        "                      learning_rate=0.01,  \n",
        "                      colsample_bytree = 0.4,\n",
        "                      subsample = 0.8,\n",
        "                      n_estimators=600, \n",
        "                      reg_alpha = 0.3,\n",
        "                      max_depth=4, \n",
        "                      gamma=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treine o modelo com o conjunto de treinamento e valide-o com o conjunto de validação\n",
        "xgb_classifier = model.fit(X_train_encoded, y_train_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_predicted = xgb_classifier.predict(X_test_transformed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y_test = y_test['coluna'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "\n",
        "# Y_true são as classes reais, Y_pred são as previsões do modelo\n",
        "accuracy = accuracy_score(y_test_transformed, y_predicted)\n",
        "\n",
        "print(\"Acurácia:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prepare data for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_enem_binary_classifier = pd.read_parquet(\"/home/cristiano/ufpr/tcc/data/data_prepared_enem_2022.parquet\")\n",
        "data_enem_binary_classifier = data_enem_binary_classifier.loc[data_enem_binary_classifier[\"TP_ESCOLA\"] != 1]\n",
        "\n",
        "\n",
        "X = data_enem_binary_classifier.drop('TP_ESCOLA', axis=1)\n",
        "y = data_enem_binary_classifier['TP_ESCOLA']\n",
        "\n",
        "# replace target values [2, 3] to [0, 1]\n",
        "y = y.replace({2: 0, 3: 1})\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA, TruncatedSVD, FastICA, KernelPCA\n",
        "from sklearn.manifold import TSNE\n",
        "from umap import UMAP\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pacmap\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "\n",
        "NUMERIC_COLS = [\n",
        "    \"TP_FAIXA_ETARIA\",\n",
        "    \"TP_ESTADO_CIVIL\",\n",
        "    \"TP_COR_RACA\",\n",
        "    \"TP_NACIONALIDADE\",\n",
        "    \"TP_ST_CONCLUSAO\",\n",
        "    \"TP_ANO_CONCLUIU\",\n",
        "    \"TP_ESCOLA\",\n",
        "    \"IN_TREINEIRO\",\n",
        "    \"CO_MUNICIPIO_PROVA\",\n",
        "    \"CO_UF_PROVA\",\n",
        "    \"TP_PRESENCA_CN\",\n",
        "    \"TP_PRESENCA_CH\",\n",
        "    \"TP_PRESENCA_LC\",\n",
        "    \"TP_PRESENCA_MT\",\n",
        "    \"NU_NOTA_CN\",\n",
        "    \"NU_NOTA_CH\",\n",
        "    \"NU_NOTA_LC\",\n",
        "    \"NU_NOTA_MT\",\n",
        "    \"TP_LINGUA\",\n",
        "    \"NU_NOTA_REDACAO\",\n",
        "    \"NU_NOTA_COMP1\",\n",
        "    \"NU_NOTA_COMP2\",\n",
        "    \"NU_NOTA_COMP3\",\n",
        "    \"NU_NOTA_COMP4\",\n",
        "    \"NU_NOTA_COMP5\"\n",
        "]\n",
        "\n",
        "CATEGORICAL_COLS = [\n",
        "    \"TP_SEXO\",\n",
        "    \"Q001\",\n",
        "    \"Q002\",\n",
        "    \"Q003\",\n",
        "    \"Q004\",\n",
        "    \"Q007\",\n",
        "    \"Q008\",\n",
        "    \"Q009\",\n",
        "    \"Q010\",\n",
        "    \"Q011\",\n",
        "    \"Q012\",\n",
        "    \"Q013\",\n",
        "    \"Q014\",\n",
        "    \"Q015\",\n",
        "    \"Q016\",\n",
        "    \"Q017\",\n",
        "    \"Q018\",\n",
        "    \"Q019\",\n",
        "    \"Q020\",\n",
        "    \"Q021\",\n",
        "    \"Q022\",\n",
        "    \"Q023\",\n",
        "    \"Q024\",\n",
        "    \"Q025\",\n",
        "    \"NO_MUNICIPIO_PROVA\",\n",
        "    \"TP_STATUS_REDACAO\",\n",
        "    \"SG_UF_PROVA\",\n",
        "]\n",
        "\n",
        "\n",
        "def generate_pipeline(method, n_components=None):\n",
        "    numeric_transformer = Pipeline(steps=[(\"scaler\", MinMaxScaler())])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[(\"encoder\", OrdinalEncoder())])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"cat\", categorical_transformer, CATEGORICAL_COLS),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if method == \"nan\":\n",
        "        return Pipeline(steps=[(\"preprocessor\", preprocessor)])\n",
        "\n",
        "    elif method == \"pca\":\n",
        "        return Pipeline(\n",
        "            steps=[\n",
        "                (\"preprocessor\", preprocessor),\n",
        "                (\"reduction_method\", PCA(n_components=n_components)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    elif method == \"svd\":\n",
        "        return Pipeline(\n",
        "            steps=[\n",
        "                (\"preprocessor\", preprocessor),\n",
        "                (\"reduction_method\", TruncatedSVD(n_components=n_components)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    elif method == \"ica\":\n",
        "        return Pipeline(\n",
        "            steps=[\n",
        "                (\"preprocessor\", preprocessor),\n",
        "                (\"reduction_method\", FastICA(n_components=n_components)),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    elif method == \"tsne\":\n",
        "        return Pipeline(\n",
        "            steps=[\n",
        "                (\"preprocessor\", preprocessor),\n",
        "                (\"pre_tsne\", PCA(n_components=5)),\n",
        "                (\"reduction_method\", TSNE(n_components=n_components)),\n",
        "            ]\n",
        "        )\n",
        "    elif method == 'pacmap':\n",
        "        return Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('reduction_method', pacmap.PaCMAP(n_components=n_components, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0))\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Suponha que você tenha seus datasets X_train e y_train\n",
        "\n",
        "# Lista de colunas categóricas\n",
        "categorical_cols = [\n",
        "    \"TP_SEXO\",\n",
        "    \"Q001\",\n",
        "    \"Q002\",\n",
        "    \"Q003\",\n",
        "    \"Q004\",\n",
        "    \"Q007\",\n",
        "    \"Q008\",\n",
        "    \"Q009\",\n",
        "    \"Q010\",\n",
        "    \"Q011\",\n",
        "    \"Q012\",\n",
        "    \"Q013\",\n",
        "    \"Q014\",\n",
        "    \"Q015\",\n",
        "    \"Q016\",\n",
        "    \"Q017\",\n",
        "    \"Q018\",\n",
        "    \"Q019\",\n",
        "    \"Q020\",\n",
        "    \"Q021\",\n",
        "    \"Q022\",\n",
        "    \"Q023\",\n",
        "    \"Q024\",\n",
        "    \"Q025\",\n",
        "    \"NO_MUNICIPIO_PROVA\",\n",
        "    \"TP_STATUS_REDACAO\",\n",
        "    \"SG_UF_PROVA\"\n",
        "]\n",
        "\n",
        "# Pipeline para aplicar codificadores\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('ordinal_encoder', OrdinalEncoder(), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Crie o pipeline\n",
        "train_pipeline = Pipeline(steps=[    \n",
        "    ('preprocessor', preprocessor)\n",
        "])\n",
        "\n",
        "# Ajuste o pipeline ao conjunto de dados de treinamento\n",
        "X_train_encoded = train_pipeline.fit_transform(X_train)\n",
        "\n",
        "X_test_transformed = train_pipeline.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1054048, 53)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1054048,)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(silent=False, \n",
        "                      scale_pos_weight=1,\n",
        "                      n_estimators=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reduction method: pca - n_components: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:06] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:12] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:18] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:24] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:30] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:37] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy médio na validação cruzada: 0.8774477079920906\n",
            "Accuracy no conjunto de teste: 0.8779182731716203\n",
            "Reduction method: pca - n_components: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:52] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:37:58] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:38:05] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:38:12] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:38:19] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:38:27] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy médio na validação cruzada: 0.8787142527425708\n",
            "Accuracy no conjunto de teste: 0.8793413582683142\n",
            "Reduction method: pca - n_components: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:38:45] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:38:53] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:39:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:39:06] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:39:14] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:39:23] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy médio na validação cruzada: 0.8863495781116277\n",
            "Accuracy no conjunto de teste: 0.886878016940405\n",
            "Reduction method: pca - n_components: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:39:44] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:39:57] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:40:08] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:40:23] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:40:33] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:40:42] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy médio na validação cruzada: 0.8953994493269428\n",
            "Accuracy no conjunto de teste: 0.8953292449679711\n",
            "Reduction method: pca - n_components: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:41:05] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:41:16] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/home/cristiano/envs/tcc/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [15:41:29] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"silent\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "k_folds = 5\n",
        "\n",
        "reduction_method_list = ['pca', 'svd', 'ica']\n",
        "n_components_list = [2, 3, 5, 10, 20]\n",
        "src_path = \"/home/cristiano/ufpr/data_train/binaria/\"\n",
        "\n",
        "df_linear_results = pd.DataFrame()\n",
        "results_list = []\n",
        "\n",
        "for reduction_method in reduction_method_list:\n",
        "    for n in n_components_list:\n",
        "        results = {}\n",
        "        print(f\"Reduction method: {reduction_method} - n_components: {n}\")\n",
        "        \n",
        "        pipe = generate_pipeline(reduction_method, n)\n",
        "        \n",
        "        X_train_method = pipe.fit_transform(X_train)\n",
        "        X_test_transformed = pipe.transform(X_test)\n",
        "    \n",
        "        kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "        cv_results = cross_val_score(model, X_train_method, y_train, cv=kf)\n",
        "        \n",
        "        # get training time\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train_method, y_train)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        # save model\n",
        "        with open(f'{src_path}/model_{reduction_method}_{n}.pkl', 'wb') as file:\n",
        "            pickle.dump(model, file)\n",
        "        \n",
        "        training_time = end_time - start_time\n",
        "        \n",
        "        y_predicted = model.predict(X_test_transformed)\n",
        "        \n",
        "        # get classification metrics\n",
        "        test_accuracy = accuracy_score(y_test, y_predicted)\n",
        "        test_f1_score = f1_score(y_test, y_predicted)\n",
        "        test_precision = precision_score(y_test, y_predicted)\n",
        "        test_recall = recall_score(y_test, y_predicted)\n",
        "\n",
        "        print(\"Accuracy médio na validação cruzada:\", np.mean(cv_results))\n",
        "        print(\"Accuracy no conjunto de test3.458000e:\", test_accuracy)\n",
        "        \n",
        "        # Adicionando métricas ao dicionário de resultados\n",
        "        results['Reduction Method'] = reduction_method\n",
        "        results['n_components'] = n\n",
        "        results['CV Accuracy'] = np.mean(cv_results)\n",
        "        results['Test Accuracy'] = test_accuracy\n",
        "        results['Test F1 Score'] = test_f1_score\n",
        "        results['Test Precision'] = test_precision\n",
        "        results['Test Recall'] = test_recall\n",
        "        results['Training Time'] = training_time\n",
        "        3.458000\n",
        "# Criando DataFrame a partir da lista de resultados\n",
        "df_linear_results = pd.DataFrame(results_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_linear = pd.read_parquet('/home/cristiano/ufpr/resultados-classificacao-binaria/data-results/linear_results.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reduction Method</th>\n",
              "      <th>n_components</th>\n",
              "      <th>CV Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Test F1 Score</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pca</td>\n",
              "      <td>2</td>\n",
              "      <td>0.877247</td>\n",
              "      <td>0.877918</td>\n",
              "      <td>0.531528</td>\n",
              "      <td>0.697257</td>\n",
              "      <td>0.429452</td>\n",
              "      <td>3.537254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pca</td>\n",
              "      <td>3</td>\n",
              "      <td>0.879066</td>\n",
              "      <td>0.879398</td>\n",
              "      <td>0.532179</td>\n",
              "      <td>0.710646</td>\n",
              "      <td>0.425358</td>\n",
              "      <td>3.689495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pca</td>\n",
              "      <td>5</td>\n",
              "      <td>0.886314</td>\n",
              "      <td>0.886874</td>\n",
              "      <td>0.580755</td>\n",
              "      <td>0.721721</td>\n",
              "      <td>0.485857</td>\n",
              "      <td>4.676369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pca</td>\n",
              "      <td>10</td>\n",
              "      <td>0.895373</td>\n",
              "      <td>0.895618</td>\n",
              "      <td>0.632135</td>\n",
              "      <td>0.732216</td>\n",
              "      <td>0.556123</td>\n",
              "      <td>5.713344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pca</td>\n",
              "      <td>20</td>\n",
              "      <td>0.896044</td>\n",
              "      <td>0.896183</td>\n",
              "      <td>0.634660</td>\n",
              "      <td>0.733735</td>\n",
              "      <td>0.559159</td>\n",
              "      <td>7.479218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svd</td>\n",
              "      <td>2</td>\n",
              "      <td>0.866887</td>\n",
              "      <td>0.866689</td>\n",
              "      <td>0.457810</td>\n",
              "      <td>0.665216</td>\n",
              "      <td>0.348998</td>\n",
              "      <td>3.837038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svd</td>\n",
              "      <td>3</td>\n",
              "      <td>0.871754</td>\n",
              "      <td>0.872336</td>\n",
              "      <td>0.490435</td>\n",
              "      <td>0.688220</td>\n",
              "      <td>0.380954</td>\n",
              "      <td>4.215442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svd</td>\n",
              "      <td>5</td>\n",
              "      <td>0.883908</td>\n",
              "      <td>0.884335</td>\n",
              "      <td>0.567569</td>\n",
              "      <td>0.714689</td>\n",
              "      <td>0.470680</td>\n",
              "      <td>4.332050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svd</td>\n",
              "      <td>10</td>\n",
              "      <td>0.894217</td>\n",
              "      <td>0.894608</td>\n",
              "      <td>0.627161</td>\n",
              "      <td>0.730120</td>\n",
              "      <td>0.549652</td>\n",
              "      <td>5.170782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>svd</td>\n",
              "      <td>20</td>\n",
              "      <td>0.894793</td>\n",
              "      <td>0.895291</td>\n",
              "      <td>0.629419</td>\n",
              "      <td>0.733166</td>\n",
              "      <td>0.551393</td>\n",
              "      <td>7.158125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ica</td>\n",
              "      <td>2</td>\n",
              "      <td>0.878081</td>\n",
              "      <td>0.878427</td>\n",
              "      <td>0.532007</td>\n",
              "      <td>0.701479</td>\n",
              "      <td>0.428487</td>\n",
              "      <td>3.458000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ica</td>\n",
              "      <td>3</td>\n",
              "      <td>0.878199</td>\n",
              "      <td>0.878563</td>\n",
              "      <td>0.520427</td>\n",
              "      <td>0.716591</td>\n",
              "      <td>0.408580</td>\n",
              "      <td>3.843519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ica</td>\n",
              "      <td>5</td>\n",
              "      <td>0.886236</td>\n",
              "      <td>0.886426</td>\n",
              "      <td>0.578728</td>\n",
              "      <td>0.720136</td>\n",
              "      <td>0.483740</td>\n",
              "      <td>4.981772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ica</td>\n",
              "      <td>10</td>\n",
              "      <td>0.894432</td>\n",
              "      <td>0.894612</td>\n",
              "      <td>0.627260</td>\n",
              "      <td>0.730013</td>\n",
              "      <td>0.549864</td>\n",
              "      <td>5.904160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ica</td>\n",
              "      <td>20</td>\n",
              "      <td>0.892847</td>\n",
              "      <td>0.893382</td>\n",
              "      <td>0.620405</td>\n",
              "      <td>0.728464</td>\n",
              "      <td>0.540263</td>\n",
              "      <td>7.075363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Reduction Method  n_components  CV Accuracy  Test Accuracy  Test F1 Score  \\\n",
              "0               pca             2     0.877247       0.877918       0.531528   \n",
              "1               pca             3     0.879066       0.879398       0.532179   \n",
              "2               pca             5     0.886314       0.886874       0.580755   \n",
              "3               pca            10     0.895373       0.895618       0.632135   \n",
              "4               pca            20     0.896044       0.896183       0.634660   \n",
              "5               svd             2     0.866887       0.866689       0.457810   \n",
              "6               svd             3     0.871754       0.872336       0.490435   \n",
              "7               svd             5     0.883908       0.884335       0.567569   \n",
              "8               svd            10     0.894217       0.894608       0.627161   \n",
              "9               svd            20     0.894793       0.895291       0.629419   \n",
              "10              ica             2     0.878081       0.878427       0.532007   \n",
              "11              ica             3     0.878199       0.878563       0.520427   \n",
              "12              ica             5     0.886236       0.886426       0.578728   \n",
              "13              ica            10     0.894432       0.894612       0.627260   \n",
              "14              ica            20     0.892847       0.893382       0.620405   \n",
              "\n",
              "    Test Precision  Test Recall  Training Time  \n",
              "0         0.697257     0.429452       3.537254  \n",
              "1         0.710646     0.425358       3.689495  \n",
              "2         0.721721     0.485857       4.676369  \n",
              "3         0.732216     0.556123       5.713344  \n",
              "4         0.733735     0.559159       7.479218  \n",
              "5         0.665216     0.348998       3.837038  \n",
              "6         0.688220     0.380954       4.215442  \n",
              "7         0.714689     0.470680       4.332050  \n",
              "8         0.730120     0.549652       5.170782  \n",
              "9         0.733166     0.551393       7.158125  \n",
              "10        0.701479     0.428487       3.458000  \n",
              "11        0.716591     0.408580       3.843519  \n",
              "12        0.720136     0.483740       4.981772  \n",
              "13        0.730013     0.549864       5.904160  \n",
              "14        0.728464     0.540263       7.075363  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_results_linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_baseline = pd.read_parquet('/home/cristiano/ufpr/resultados-classificacao-binaria/data-results/baseline-binary.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reduction Method</th>\n",
              "      <th>n_components</th>\n",
              "      <th>CV Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Test F1 Score</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nan</td>\n",
              "      <td>None</td>\n",
              "      <td>0.899069</td>\n",
              "      <td>0.8989</td>\n",
              "      <td>0.645953</td>\n",
              "      <td>0.742054</td>\n",
              "      <td>0.571889</td>\n",
              "      <td>7.920424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Reduction Method n_components  CV Accuracy  Test Accuracy  Test F1 Score  \\\n",
              "0              nan         None     0.899069         0.8989       0.645953   \n",
              "\n",
              "   Test Precision  Test Recall  Training Time  \n",
              "0        0.742054     0.571889       7.920424  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "base = pd.read_parquet('/home/cristiano/ufpr/resultados-classificacao-binaria/data-results/data_prepared_enem_2022.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_enem_binary_classifier = base.loc[base[\"TP_ESCOLA\"] != 1]                   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TP_ESCOLA\n",
              "2    1105355\n",
              "3     212205\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_enem_binary_classifier[\"TP_ESCOLA\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_results_linear_v2 = pd.read_parquet('/home/cristiano/ufpr/resultados-classificacao-binaria/linear-results-v2.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reduction Method</th>\n",
              "      <th>n_components</th>\n",
              "      <th>CV Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Test F1 Score</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pca</td>\n",
              "      <td>2</td>\n",
              "      <td>0.797981</td>\n",
              "      <td>0.798818</td>\n",
              "      <td>0.557848</td>\n",
              "      <td>0.432058</td>\n",
              "      <td>0.786968</td>\n",
              "      <td>4.138487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pca</td>\n",
              "      <td>3</td>\n",
              "      <td>0.795223</td>\n",
              "      <td>0.795960</td>\n",
              "      <td>0.555185</td>\n",
              "      <td>0.428099</td>\n",
              "      <td>0.789580</td>\n",
              "      <td>4.246294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pca</td>\n",
              "      <td>5</td>\n",
              "      <td>0.817387</td>\n",
              "      <td>0.817371</td>\n",
              "      <td>0.588066</td>\n",
              "      <td>0.462136</td>\n",
              "      <td>0.808335</td>\n",
              "      <td>4.135391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pca</td>\n",
              "      <td>10</td>\n",
              "      <td>0.840429</td>\n",
              "      <td>0.837871</td>\n",
              "      <td>0.622838</td>\n",
              "      <td>0.498396</td>\n",
              "      <td>0.830102</td>\n",
              "      <td>5.158190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pca</td>\n",
              "      <td>20</td>\n",
              "      <td>0.845575</td>\n",
              "      <td>0.842922</td>\n",
              "      <td>0.628071</td>\n",
              "      <td>0.508024</td>\n",
              "      <td>0.822407</td>\n",
              "      <td>7.303978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svd</td>\n",
              "      <td>2</td>\n",
              "      <td>0.772588</td>\n",
              "      <td>0.773506</td>\n",
              "      <td>0.521525</td>\n",
              "      <td>0.395504</td>\n",
              "      <td>0.765413</td>\n",
              "      <td>3.443495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svd</td>\n",
              "      <td>3</td>\n",
              "      <td>0.778724</td>\n",
              "      <td>0.778712</td>\n",
              "      <td>0.535644</td>\n",
              "      <td>0.404815</td>\n",
              "      <td>0.791416</td>\n",
              "      <td>3.674541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svd</td>\n",
              "      <td>5</td>\n",
              "      <td>0.811656</td>\n",
              "      <td>0.810722</td>\n",
              "      <td>0.577245</td>\n",
              "      <td>0.451109</td>\n",
              "      <td>0.801299</td>\n",
              "      <td>5.391796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svd</td>\n",
              "      <td>10</td>\n",
              "      <td>0.837707</td>\n",
              "      <td>0.835867</td>\n",
              "      <td>0.618742</td>\n",
              "      <td>0.494679</td>\n",
              "      <td>0.825866</td>\n",
              "      <td>5.637844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>svd</td>\n",
              "      <td>20</td>\n",
              "      <td>0.843313</td>\n",
              "      <td>0.840595</td>\n",
              "      <td>0.623101</td>\n",
              "      <td>0.503560</td>\n",
              "      <td>0.817065</td>\n",
              "      <td>7.767753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ica</td>\n",
              "      <td>2</td>\n",
              "      <td>0.794259</td>\n",
              "      <td>0.794214</td>\n",
              "      <td>0.554856</td>\n",
              "      <td>0.426055</td>\n",
              "      <td>0.795275</td>\n",
              "      <td>4.014672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ica</td>\n",
              "      <td>3</td>\n",
              "      <td>0.789813</td>\n",
              "      <td>0.791546</td>\n",
              "      <td>0.549924</td>\n",
              "      <td>0.421848</td>\n",
              "      <td>0.789674</td>\n",
              "      <td>4.550048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ica</td>\n",
              "      <td>5</td>\n",
              "      <td>0.817722</td>\n",
              "      <td>0.817261</td>\n",
              "      <td>0.587150</td>\n",
              "      <td>0.461843</td>\n",
              "      <td>0.805770</td>\n",
              "      <td>4.209231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ica</td>\n",
              "      <td>10</td>\n",
              "      <td>0.838445</td>\n",
              "      <td>0.836322</td>\n",
              "      <td>0.619337</td>\n",
              "      <td>0.495516</td>\n",
              "      <td>0.825654</td>\n",
              "      <td>6.092211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ica</td>\n",
              "      <td>20</td>\n",
              "      <td>0.839015</td>\n",
              "      <td>0.836038</td>\n",
              "      <td>0.615482</td>\n",
              "      <td>0.494919</td>\n",
              "      <td>0.813700</td>\n",
              "      <td>8.266166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Reduction Method  n_components  CV Accuracy  Test Accuracy  Test F1 Score  \\\n",
              "0               pca             2     0.797981       0.798818       0.557848   \n",
              "1               pca             3     0.795223       0.795960       0.555185   \n",
              "2               pca             5     0.817387       0.817371       0.588066   \n",
              "3               pca            10     0.840429       0.837871       0.622838   \n",
              "4               pca            20     0.845575       0.842922       0.628071   \n",
              "5               svd             2     0.772588       0.773506       0.521525   \n",
              "6               svd             3     0.778724       0.778712       0.535644   \n",
              "7               svd             5     0.811656       0.810722       0.577245   \n",
              "8               svd            10     0.837707       0.835867       0.618742   \n",
              "9               svd            20     0.843313       0.840595       0.623101   \n",
              "10              ica             2     0.794259       0.794214       0.554856   \n",
              "11              ica             3     0.789813       0.791546       0.549924   \n",
              "12              ica             5     0.817722       0.817261       0.587150   \n",
              "13              ica            10     0.838445       0.836322       0.619337   \n",
              "14              ica            20     0.839015       0.836038       0.615482   \n",
              "\n",
              "    Test Precision  Test Recall  Training Time  \n",
              "0         0.432058     0.786968       4.138487  \n",
              "1         0.428099     0.789580       4.246294  \n",
              "2         0.462136     0.808335       4.135391  \n",
              "3         0.498396     0.830102       5.158190  \n",
              "4         0.508024     0.822407       7.303978  \n",
              "5         0.395504     0.765413       3.443495  \n",
              "6         0.404815     0.791416       3.674541  \n",
              "7         0.451109     0.801299       5.391796  \n",
              "8         0.494679     0.825866       5.637844  \n",
              "9         0.503560     0.817065       7.767753  \n",
              "10        0.426055     0.795275       4.014672  \n",
              "11        0.421848     0.789674       4.550048  \n",
              "12        0.461843     0.805770       4.209231  \n",
              "13        0.495516     0.825654       6.092211  \n",
              "14        0.494919     0.813700       8.266166  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_results_linear_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.208901769515327"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1105355 / 212205"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "btc_mlops",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
